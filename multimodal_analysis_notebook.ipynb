{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# Multimodal Analysis with Snowflake Cortex AI\n",
    "\n",
    "This notebook demonstrates how to use Snowflake Cortex AI for comprehensive multimodal analysis, including image analysis with AI_COMPLETE and audio transcription with AI_TRANSCRIBE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required packages and set up our session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import json\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Setup session\n",
    "session = get_active_session()\n",
    "session.use_schema(\"MULTIMODAL_ANALYSIS.MEDIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b3898-aef5-4389-b08a-3c9a2c55008f",
   "metadata": {
    "language": "sql",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "-- Create an image table that references the files in our stage\n",
    "CREATE OR REPLACE TABLE MULTIMODAL_ANALYSIS.MEDIA.IMAGE_TABLE AS\n",
    "  SELECT \n",
    "    RELATIVE_PATH AS image_path,\n",
    "    TO_FILE('@MULTIMODAL_ANALYSIS.MEDIA.IMAGES', RELATIVE_PATH) AS img_file\n",
    "  FROM DIRECTORY('@MULTIMODAL_ANALYSIS.MEDIA.IMAGES');\n",
    "\n",
    "-- Create an audio table that references the files in our stage\n",
    "CREATE OR REPLACE TABLE MULTIMODAL_ANALYSIS.MEDIA.AUDIO_TABLE AS\n",
    "  SELECT \n",
    "    RELATIVE_PATH AS audio_path,\n",
    "    TO_FILE('@MULTIMODAL_ANALYSIS.MEDIA.AUDIO', RELATIVE_PATH) AS audio_file\n",
    "  FROM DIRECTORY('@MULTIMODAL_ANALYSIS.MEDIA.AUDIO');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "name": "cell4"
   },
   "source": [
    "## View Available Media Files\n",
    "\n",
    "Let's see what images and audio files we have available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "# View available images\n",
    "image_df = session.sql(\"SELECT * FROM IMAGE_TABLE\").collect()\n",
    "print(f\"Found {len(image_df)} images in the stage\")\n",
    "\n",
    "# Display the first few images\n",
    "for i, row in enumerate(image_df[:3]):\n",
    "    print(f\"Image {i+1}: {row['IMAGE_PATH']}\")\n",
    "\n",
    "# View available audio files\n",
    "audio_df = session.sql(\"SELECT * FROM AUDIO_TABLE\").collect()\n",
    "print(f\"\\nFound {len(audio_df)} audio files in the stage\")\n",
    "\n",
    "# Display the first few audio files\n",
    "for i, row in enumerate(audio_df[:3]):\n",
    "    print(f\"Audio {i+1}: {row['AUDIO_PATH']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "name": "cell6"
   },
   "source": [
    "## Image Analysis with AI_COMPLETE\n",
    "\n",
    "Create a function to analyze images with AI_COMPLETE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# Function to analyze an image with chosen AI model\n",
    "def analyze_image(image_path, prompt_template, model='claude-3-5-sonnet'):\n",
    "    # Escape single quotes in the prompt\n",
    "    escaped_prompt = prompt_template.replace(\"'\", \"''\")\n",
    "    \n",
    "    sql_query = f\"\"\"\n",
    "    SELECT \n",
    "      AI_COMPLETE(\n",
    "        '{model}', \n",
    "        '{escaped_prompt}',\n",
    "         TO_FILE('@IMAGES', '{image_path}')\n",
    "      )\n",
    "    \"\"\"\n",
    "    result = session.sql(sql_query).collect()\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "name": "cell8"
   },
   "source": [
    "## Basic Image Analysis\n",
    "\n",
    "Let's analyze our first image with a custom prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": [
    "# Example analysis with custom prompt\n",
    "if len(image_df) > 0:\n",
    "    image_path = image_df[0]['IMAGE_PATH']  # Get first image\n",
    "    prompt = \"Describe what's happening in this image in the style of a detective investigating a scene. Be brief but detailed.\"\n",
    "\n",
    "    analysis = analyze_image(image_path, prompt)\n",
    "    print(f\"Analysis for {image_path}:\")\n",
    "    print(analysis)\n",
    "else:\n",
    "    print(\"No images found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "name": "cell10"
   },
   "source": [
    "## Object Detection\n",
    "\n",
    "Now let's identify objects in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "# Object detection\n",
    "if len(image_df) > 0:\n",
    "    image_path = image_df[0]['IMAGE_PATH']\n",
    "    object_prompt = \"List all visible objects in this image and count how many there are of each type.\"\n",
    "    object_analysis = analyze_image(image_path, object_prompt)\n",
    "    print(\"Objects detected:\")\n",
    "    print(object_analysis)\n",
    "else:\n",
    "    print(\"No images found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "name": "cell12"
   },
   "source": [
    "## Text Extraction from Images\n",
    "\n",
    "Let's extract any visible text from the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "# Text extraction\n",
    "if len(image_df) > 0:\n",
    "    image_path = image_df[4]['IMAGE_PATH']\n",
    "    text_prompt = \"Extract and transcribe any visible text in this image. If no text is visible, respond with 'No text detected'.\"\n",
    "    text_analysis = analyze_image(image_path, text_prompt)\n",
    "    print(\"Text extracted:\")\n",
    "    print(text_analysis)\n",
    "else:\n",
    "    print(\"No images found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "name": "cell14"
   },
   "source": [
    "## Compare Different Models\n",
    "\n",
    "Let's compare Claude 3.5 Sonnet with Pixtral-large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "# Try with different models\n",
    "if len(image_df) > 0:\n",
    "    image_path = image_df[0]['IMAGE_PATH']\n",
    "    prompt = \"Describe what you see in this image. Be detailed but concise.\"\n",
    "    \n",
    "    # Claude analysis\n",
    "    claude_analysis = analyze_image(image_path, prompt, model='claude-4-sonnet')\n",
    "    print(f\"Claude 4 Sonnet analysis for {image_path}:\")\n",
    "    print(claude_analysis)\n",
    "    \n",
    "    # Pixtral analysis\n",
    "    pixtral_analysis = analyze_image(image_path, prompt, model='pixtral-large')\n",
    "    print(f\"\\nPixtral-large analysis for {image_path}:\")\n",
    "    print(pixtral_analysis)\n",
    "else:\n",
    "    print(\"No images found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "metadata": {
    "name": "cell16"
   },
   "source": [
    "## Audio Transcription with AI_TRANSCRIBE\n",
    "\n",
    "Now let's work with audio files using AI_TRANSCRIBE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "# Function to transcribe audio with different modes\n",
    "def transcribe_audio(audio_path, mode='text'):\n",
    "    mode_options = {\n",
    "        'text': None,  # No second parameter for text mode\n",
    "        'word': \"{'timestamp_granularity': 'word'}\",\n",
    "        'speaker': \"{'timestamp_granularity': 'speaker'}\"\n",
    "    }\n",
    "    \n",
    "    if mode_options[mode] is None:\n",
    "        sql_query = f\"\"\"\n",
    "        SELECT AI_TRANSCRIBE(\n",
    "            TO_FILE('@AUDIO', '{audio_path}')\n",
    "        ) as transcription_result\n",
    "        \"\"\"\n",
    "    else:\n",
    "        sql_query = f\"\"\"\n",
    "        SELECT AI_TRANSCRIBE(\n",
    "            TO_FILE('@AUDIO', '{audio_path}'),\n",
    "            {mode_options[mode]}\n",
    "        ) as transcription_result\n",
    "        \"\"\"\n",
    "    \n",
    "    result = session.sql(sql_query).collect()\n",
    "    print(result)\n",
    "    return json.loads(result[0]['TRANSCRIPTION_RESULT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "metadata": {
    "name": "cell18"
   },
   "source": [
    "## Basic Audio Transcription\n",
    "\n",
    "Let's transcribe our first audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000018",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "# Basic text transcription\n",
    "if len(audio_df) > 0:\n",
    "    audio_path = audio_df[0]['AUDIO_PATH']\n",
    "    word_transcription = transcribe_audio(audio_path, mode='text')\n",
    "    \n",
    "    print(f\"Transcription for {audio_path}:\")\n",
    "    print(f\"Duration: {word_transcription['audio_duration']} seconds\")\n",
    "    print(f\"Text: {word_transcription['text']}\")\n",
    "else:\n",
    "    print(\"No audio files found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000019",
   "metadata": {
    "name": "cell20"
   },
   "source": [
    "## Word-Level Timestamps\n",
    "\n",
    "Let's get word-level timestamps for precise navigation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000020",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "# Word-level transcription\n",
    "if len(audio_df) > 0:\n",
    "    audio_path = audio_df[0]['AUDIO_PATH']\n",
    "    word_transcription = transcribe_audio(audio_path, mode='word')\n",
    "    \n",
    "    print(f\"Word-level transcription for {audio_path}:\")\n",
    "    print(f\"Duration: {word_transcription['audio_duration']} seconds\")\n",
    "    print(\"First 10 words with timestamps:\")\n",
    "    \n",
    "    for segment in word_transcription['segments'][:10]:\n",
    "        print(f\"  {segment['start']:.2f}s - {segment['end']:.2f}s: {segment['text']}\")\n",
    "else:\n",
    "    print(\"No audio files found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000021",
   "metadata": {
    "name": "cell22"
   },
   "source": [
    "## Speaker Identification\n",
    "\n",
    "Let's identify different speakers in the audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000022",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "# Speaker identification\n",
    "if len(audio_df) > 0:\n",
    "    audio_path = audio_df[0]['AUDIO_PATH']\n",
    "    speaker_transcription = transcribe_audio(audio_path, mode='speaker')\n",
    "    \n",
    "    print(f\"Speaker-segmented transcription for {audio_path}:\")\n",
    "    print(f\"Duration: {speaker_transcription['audio_duration']} seconds\")\n",
    "    \n",
    "    # Group by speaker\n",
    "    speakers = {}\n",
    "    for segment in speaker_transcription['segments']:\n",
    "        speaker = segment['speaker_label']\n",
    "        if speaker not in speakers:\n",
    "            speakers[speaker] = []\n",
    "        speakers[speaker].append(segment['text'])\n",
    "    \n",
    "    for speaker, texts in speakers.items():\n",
    "        print(f\"\\n{speaker}:\")\n",
    "        print(\" \".join(texts[:3]))  # Show first 3 segments\n",
    "else:\n",
    "    print(\"No audio files found in the table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000031",
   "metadata": {
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the full capabilities of Snowflake Cortex AI for multimodal analysis, combining powerful image analysis with AI_COMPLETE and comprehensive audio processing with AI_TRANSCRIBE.\n",
    "\n",
    "Key takeaways:\n",
    "- **AI_COMPLETE** provides sophisticated image analysis capabilities with multiple model options\n",
    "- **AI_TRANSCRIBE** offers flexible audio processing with text, word-level, and speaker identification modes\n",
    "\n",
    "Explore different combinations of prompts, models, and analysis types to find the best approach for your specific use case!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "james.cha-earley@snowflake.com",
   "authorId": "3919642301233",
   "authorName": "JAMESE",
   "lastEditTime": 1753986708911,
   "notebookId": "mgvsuixfrie27zklvb7y",
   "sessionId": "5218f53b-5a1b-4630-95e2-3fda17455266"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
